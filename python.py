# python.py
import streamlit as st
import pandas as pd
from google import genai
from google.genai.errors import APIError

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="App Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh",
    layout="wide"
)

st.title("·ª®ng d·ª•ng Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh üìä")

# ******************************* PH·∫¶N B·ªî SUNG: KH·ªûI T·∫†O STATE V√Ä H√ÄM CHAT *******************************

# Kh·ªüi t·∫°o l·ªãch s·ª≠ chat v√† d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω trong Streamlit Session State
if "messages" not in st.session_state:
    # L·ªãch s·ª≠ chat ƒë∆∞·ª£c l∆∞u tr·ªØ d∆∞·ªõi d·∫°ng danh s√°ch c√°c dict
    st.session_state.messages = [] 
if "df_processed_for_chat" not in st.session_state:
    # L∆∞u tr·ªØ DataFrame ƒë√£ x·ª≠ l√Ω ƒë·ªÉ d√πng l√†m ng·ªØ c·∫£nh cho AI
    st.session_state.df_processed_for_chat = None
if "data_context_markdown" not in st.session_state:
    # L∆∞u tr·ªØ ng·ªØ c·∫£nh d∆∞·ªõi d·∫°ng Markdown string
    st.session_state.data_context_markdown = ""

# H√†m m·ªõi ƒë·ªÉ x·ª≠ l√Ω tin nh·∫Øn chat v·ªõi ng·ªØ c·∫£nh d·ªØ li·ªáu
def chat_with_gemini(prompt, data_context, api_key, history):
    """X·ª≠ l√Ω tin nh·∫Øn chat, g·ª≠i n·ªôi dung v√† l·ªãch s·ª≠ ƒë·∫øn Gemini v·ªõi ng·ªØ c·∫£nh d·ªØ li·ªáu."""
    try:
        client = genai.Client(api_key=api_key)
        model_name = 'gemini-2.5-flash' 
        
        # Th√™m ng·ªØ c·∫£nh d·ªØ li·ªáu v√†o tin nh·∫Øn ƒë·∫ßu ti√™n c·ªßa user trong chu·ªói h·ªôi tho·∫°i
        if not history:
             context_prompt = f"""
            B·∫°n l√† m·ªôt tr·ª£ l√Ω ph√¢n t√≠ch t√†i ch√≠nh chuy√™n nghi·ªáp. H√£y tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng d·ª±a tr√™n ng·ªØ c·∫£nh d·ªØ li·ªáu sau.
            Ng·ªØ c·∫£nh d·ªØ li·ªáu t√†i ch√≠nh ƒë√£ x·ª≠ l√Ω (T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng v√† T·ª∑ tr·ªçng):
            {data_context}
            
            ƒê√¢y l√† c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {prompt}
            """
        else:
            # ƒê·ªëi v·ªõi c√°c tin nh·∫Øn ti·∫øp theo, ch·ªâ c·∫ßn th√™m c√¢u h·ªèi m·ªõi
            context_prompt = prompt
        
        # Chu·∫©n b·ªã l·ªãch s·ª≠ cho Gemini API
        gemini_history = []
        for message in history:
            gemini_history.append(
                genai.types.Content(
                    role="user" if message["role"] == "user" else "model",
                    parts=[genai.types.Part.from_text(message["content"])]
                )
            )

        # Th√™m tin nh·∫Øn user hi·ªán t·∫°i (c√≥ ch·ª©a context ho·∫∑c kh√¥ng)
        gemini_history.append(
            genai.types.Content(
                role="user", 
                parts=[genai.types.Part.from_text(context_prompt)]
            )
        )
            
        response = client.models.generate_content(
            model=model_name,
            contents=gemini_history
        )
        return response.text

    except APIError as e:
        return f"L·ªói g·ªçi Gemini API: L·ªói {e.status_code}. Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng."
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

# ******************************* K·∫æT TH√öC PH·∫¶N B·ªî SUNG *******************************

# --- H√†m t√≠nh to√°n ch√≠nh (S·ª≠ d·ª•ng Caching ƒë·ªÉ T·ªëi ∆∞u hi·ªáu su·∫•t) --- 
@st.cache_data 
def process_financial_data(df): 
    """Th·ª±c hi·ªán c√°c ph√©p t√≠nh TƒÉng tr∆∞·ªüng v√† T·ª∑ tr·ªçng.""" 
    # [Gi·ªØ nguy√™n code h√†m process_financial_data]
    # ƒê·∫£m b·∫£o c√°c gi√° tr·ªã l√† s·ªë ƒë·ªÉ t√≠nh to√°n 
    numeric_cols = ['NƒÉm tr∆∞·ªõc', 'NƒÉm sau'] 
    for col in numeric_cols: 
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) 
    
    # 1. T√≠nh T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng 
    # D√πng .replace(0, 1e-9) cho Series Pandas ƒë·ªÉ tr√°nh l·ªói chia cho 0 
    df['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'] = ( 
        (df['NƒÉm sau'] - df['NƒÉm tr∆∞·ªõc']) / df['NƒÉm tr∆∞·ªõc'].replace(0, 1e-9) 
    ) * 100 

    # 2. T√≠nh T·ª∑ tr·ªçng theo T·ªïng T√†i s·∫£n 
    # L·ªçc ch·ªâ ti√™u "T·ªîNG C·ªòNG T√ÄI S·∫¢N" 
    tong_tai_san_row = df[df['Ch·ªâ ti√™u'].str.contains('T·ªîNG C·ªòNG T√ÄI S·∫¢N', case=False, na=False)] 
    
    if tong_tai_san_row.empty: 
        raise ValueError("Kh√¥ng t√¨m th·∫•y ch·ªâ ti√™u 'T·ªîNG C·ªòNG T√ÄI S·∫¢N'.") 

    tong_tai_san_N_1 = tong_tai_san_row['NƒÉm tr∆∞·ªõc'].iloc[0] 
    tong_tai_san_N = tong_tai_san_row['NƒÉm sau'].iloc[0] 

    # ******************************* PH·∫¶N S·ª¨A L·ªñI B·∫ÆT ƒê·∫¶U ******************************* divisor_N_1 = tong_tai_san_N_1 if tong_tai_san_N_1 != 0 else 1e-9 
    divisor_N = tong_tai_san_N if tong_tai_san_N != 0 else 1e-9 

    # T√≠nh t·ª∑ tr·ªçng v·ªõi m·∫´u s·ªë ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω 
    df['T·ª∑ tr·ªçng NƒÉm tr∆∞·ªõc (%)'] = (df['NƒÉm tr∆∞·ªõc'] / divisor_N_1) * 100 
    df['T·ª∑ tr·ªçng NƒÉm sau (%)'] = (df['NƒÉm sau'] / divisor_N) * 100 
    # ******************************* PH·∫¶N S·ª¨A L·ªñI K·∫æT TH√öC ******************************* return df 

# --- H√†m g·ªçi API Gemini --- 
def get_ai_analysis(data_for_ai, api_key): 
    """G·ª≠i d·ªØ li·ªáu ph√¢n t√≠ch ƒë·∫øn Gemini API v√† nh·∫≠n nh·∫≠n x√©t.""" 
    # [Gi·ªØ nguy√™n code h√†m get_ai_analysis]
    try: 
        client = genai.Client(api_key=api_key) 
        model_name = 'gemini-2.5-flash' 

        prompt = f""" 
        B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh chuy√™n nghi·ªáp. D·ª±a tr√™n c√°c ch·ªâ s·ªë t√†i ch√≠nh sau, h√£y ƒë∆∞a ra m·ªôt nh·∫≠n x√©t kh√°ch quan, ng·∫Øn g·ªçn (kho·∫£ng 3-4 ƒëo·∫°n) v·ªÅ t√¨nh h√¨nh t√†i ch√≠nh c·ªßa doanh nghi·ªáp. ƒê√°nh gi√° t·∫≠p trung v√†o t·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng, thay ƒë·ªïi c∆° c·∫•u t√†i s·∫£n v√† kh·∫£ nƒÉng thanh to√°n hi·ªán h√†nh. 
        
        D·ªØ li·ªáu th√¥ v√† ch·ªâ s·ªë: 
        {data_for_ai} 
        """ 

        response = client.models.generate_content( 
            model=model_name, 
            contents=prompt 
        ) 
        return response.text 

    except APIError as e: 
        return f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}" 
    except KeyError: 
        return "L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API 'GEMINI_API_KEY'. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh Secrets tr√™n Streamlit Cloud." 
    except Exception as e: 
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}" 


# --- Ch·ª©c nƒÉng 1: T·∫£i File --- 
uploaded_file = st.file_uploader( 
    "1. T·∫£i file Excel B√°o c√°o T√†i ch√≠nh (Ch·ªâ ti√™u | NƒÉm tr∆∞·ªõc | NƒÉm sau)", 
    type=['xlsx', 'xls'] 
) 

if uploaded_file is not None: 
    try: 
        df_raw = pd.read_excel(uploaded_file) 
        
        # Ti·ªÅn x·ª≠ l√Ω: ƒê·∫£m b·∫£o ch·ªâ c√≥ 3 c·ªôt quan tr·ªçng 
        df_raw.columns = ['Ch·ªâ ti√™u', 'NƒÉm tr∆∞·ªõc', 'NƒÉm sau'] 
        
        # X·ª≠ l√Ω d·ªØ li·ªáu 
        df_processed = process_financial_data(df_raw.copy()) 

        # ƒê·∫∑t l·∫°i state cho Chat khi file m·ªõi ƒë∆∞·ª£c t·∫£i l√™n
        st.session_state.df_processed_for_chat = df_processed.copy()
        st.session_state.messages = []
        
        if df_processed is not None: 
            
            # --- Ch·ª©c nƒÉng 2 & 3: Hi·ªÉn th·ªã K·∫øt qu·∫£ --- 
            st.subheader("2. T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng & 3. T·ª∑ tr·ªçng C∆° c·∫•u T√†i s·∫£n") 
            st.dataframe(df_processed.style.format({ 
                'NƒÉm tr∆∞·ªõc': '{:,.0f}', 
                'NƒÉm sau': '{:,.0f}', 
                'T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)': '{:.2f}%', 
                'T·ª∑ tr·ªçng NƒÉm tr∆∞·ªõc (%)': '{:.2f}%', 
                'T·ª∑ tr·ªçng NƒÉm sau (%)': '{:.2f}%' 
            }), use_container_width=True) 
            
            # --- Ch·ª©c nƒÉng 4: T√≠nh Ch·ªâ s·ªë T√†i ch√≠nh --- 
            st.subheader("4. C√°c Ch·ªâ s·ªë T√†i ch√≠nh C∆° b·∫£n") 
            
            # Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh cho ch·ªâ s·ªë thanh to√°n
            thanh_toan_hien_hanh_N = "N/A"
            thanh_toan_hien_hanh_N_1 = "N/A"

            try: 
                # L·ªçc gi√° tr·ªã cho Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (V√≠ d·ª•) 
                
                # L·∫•y T√†i s·∫£n ng·∫Øn h·∫°n 
                tsnh_n = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm sau'].iloc[0] 
                tsnh_n_1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm tr∆∞·ªõc'].iloc[0] 

                # L·∫•y N·ª£ ng·∫Øn h·∫°n
                no_ngan_han_N = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm sau'].iloc[0]  
                no_ngan_han_N_1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm tr∆∞·ªõc'].iloc[0] 

                # T√≠nh to√°n (X·ª≠ l√Ω chia cho 0)
                thanh_toan_hien_hanh_N = tsnh_n / no_ngan_han_N if no_ngan_han_N != 0 else float('inf')
                thanh_toan_hien_hanh_N_1 = tsnh_n_1 / no_ngan_han_N_1 if no_ngan_han_N_1 != 0 else float('inf')

                col1, col2 = st.columns(2) 
                with col1: 
                    st.metric( 
                        label="Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (NƒÉm tr∆∞·ªõc)", 
                        value=f"{thanh_toan_hien_hanh_N_1:.2f} l·∫ßn" if thanh_toan_hien_hanh_N_1 != float('inf') else "V√¥ h·∫°n"
                    ) 
                with col2: 
                    st.metric( 
                        label="Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (NƒÉm sau)", 
                        value=f"{thanh_toan_hien_hanh_N:.2f} l·∫ßn" if thanh_toan_hien_hanh_N != float('inf') else "V√¥ h·∫°n",
                        delta=f"{thanh_toan_hien_hanh_N - thanh_toan_hien_hanh_N_1:.2f}" if thanh_toan_hien_hanh_N != float('inf') and thanh_toan_hien_hanh_N_1 != float('inf') else None
                    ) 
                    
            except IndexError: 
                st.warning("Thi·∫øu ch·ªâ ti√™u 'T√ÄI S·∫¢N NG·∫ÆN H·∫†N' ho·∫∑c 'N·ª¢ NG·∫ÆN H·∫†N' ƒë·ªÉ t√≠nh ch·ªâ s·ªë.") 
            except ZeroDivisionError:
                st.warning("L·ªói: N·ª£ ng·∫Øn h·∫°n b·∫±ng 0, ch·ªâ s·ªë thanh to√°n hi·ªán h√†nh l√† v√¥ h·∫°n.")
            
            # --- Ch·ª©c nƒÉng 5: Nh·∫≠n x√©t AI --- 
            
            # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ g·ª≠i cho AI (cho c·∫£ Ch·ª©c nƒÉng 5 v√† Khung chat)
            
            # L·∫•y t·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng TSNH (c·∫ßn chu·∫©n b·ªã l·∫°i v√¨ c√°c block try/except ·ªü tr√™n)
            try:
                tsnh_tang_truong = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'].iloc[0]
            except IndexError:
                tsnh_tang_truong = "N/A"

            # Chuy·ªÉn ƒë·ªïi c√°c ch·ªâ s·ªë sang chu·ªói ƒë·ªÉ ƒë∆∞a v√†o Markdown
            thh_n_str = f"{thanh_toan_hien_hanh_N:.2f}" if isinstance(thanh_toan_hien_hanh_N, (float, int)) and thanh_toan_hien_hanh_N != float('inf') else str(thanh_toan_hien_hanh_N)
            thh_n_1_str = f"{thanh_toan_hien_hanh_N_1:.2f}" if isinstance(thanh_toan_hien_hanh_N_1, (float, int)) and thanh_toan_hien_hanh_N_1 != float('inf') else str(thanh_toan_hien_hanh_N_1)
            
            data_for_ai_df = pd.DataFrame({ 
                'Ch·ªâ ti√™u': [ 
                    'To√†n b·ªô B·∫£ng ph√¢n t√≠ch (d·ªØ li·ªáu th√¥)', 
                    'TƒÉng tr∆∞·ªüng T√†i s·∫£n ng·∫Øn h·∫°n (%)', 
                    'Thanh to√°n hi·ªán h√†nh (N-1)', 
                    'Thanh to√°n hi·ªán h√†nh (N)' 
                ], 
                'Gi√° tr·ªã': [ 
                    df_processed.to_markdown(index=False), 
                    f"{tsnh_tang_truong:.2f}%" if isinstance(tsnh_tang_truong, (float, int)) else tsnh_tang_truong, 
                    thh_n_1_str, 
                    thh_n_str
                ] 
            }) 

            # L∆∞u ng·ªØ c·∫£nh v√†o Session State ƒë·ªÉ h√†m Chat c√≥ th·ªÉ s·ª≠ d·ª•ng
            st.session_state.data_context_markdown = data_for_ai_df.to_markdown(index=False)
            
            # Ti·∫øp t·ª•c Ch·ª©c nƒÉng 5
            st.subheader("5. Nh·∫≠n x√©t T√¨nh h√¨nh T√†i ch√≠nh (AI)") 
            if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch"): 
                api_key = st.secrets.get("GEMINI_API_KEY") 
                
                if api_key: 
                    with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'): 
                        ai_result = get_ai_analysis(st.session_state.data_context_markdown, api_key) 
                        st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**") 
                        st.info(ai_result) 
                else: 
                    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets.") 
            
            # ******************************* PH·∫¶N B·ªî SUNG: KHUNG CHAT (CH·ª®C NƒÇNG 6) *******************************
            st.markdown("---")
            st.subheader("6. Chat v·ªõi Gemini AI ƒë·ªÉ Ph√¢n t√≠ch chuy√™n s√¢u üí¨")
            st.caption("AI s·∫Ω nh·ªõ l·ªãch s·ª≠ chat v√† c√≥ ng·ªØ c·∫£nh l√† B√°o c√°o t√†i ch√≠nh b·∫°n v·ª´a t·∫£i l√™n.")

            # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

            # X·ª≠ l√Ω input chat
            if prompt := st.chat_input("B·∫°n mu·ªën h·ªèi g√¨ v·ªÅ B√°o c√°o t√†i ch√≠nh n√†y? (VD: ƒê√°nh gi√° c∆° c·∫•u t√†i s·∫£n)"):
                
                # Th√™m tin nh·∫Øn c·ªßa user v√†o l·ªãch s·ª≠ v√† hi·ªÉn th·ªã
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                api_key = st.secrets.get("GEMINI_API_KEY") 

                if not api_key:
                    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets.")
                    # Kh√¥ng x√≥a tin nh·∫Øn user ƒë·ªÉ ng∆∞·ªùi d√πng th·∫•y l·ªói
                elif st.session_state.df_processed_for_chat is None:
                     st.error("L·ªói: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu t√†i ch√≠nh ƒë√£ x·ª≠ l√Ω. Vui l√≤ng t·∫£i l·∫°i file.")
                else:
                    with st.chat_message("assistant"):
                        with st.spinner("ƒêang ch·ªù Gemini ph·∫£n h·ªìi..."):
                            # G·ªçi h√†m chat v·ªõi ng·ªØ c·∫£nh v√† l·ªãch s·ª≠
                            full_response = chat_with_gemini(
                                prompt=prompt, 
                                data_context=st.session_state.data_context_markdown, # Ng·ªØ c·∫£nh d·ªØ li·ªáu ƒë√£ l∆∞u
                                api_key=api_key,
                                history=st.session_state.messages[:-1] # L·ªãch s·ª≠ tr·ª´ tin nh·∫Øn m·ªõi nh·∫•t
                            )
                            
                            st.markdown(full_response)
                        
                        # Th√™m ph·∫£n h·ªìi c·ªßa AI v√†o l·ªãch s·ª≠ chat
                        st.session_state.messages.append({"role": "assistant", "content": full_response})

            # ******************************* K·∫æT TH√öC PH·∫¶N B·ªî SUNG *******************************
            
    except ValueError as ve: 
        st.error(f"L·ªói c·∫•u tr√∫c d·ªØ li·ªáu: {ve}") 
    except Exception as e: 
        st.error(f"C√≥ l·ªói x·∫£y ra khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file: {e}. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file.") 

else: 
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
